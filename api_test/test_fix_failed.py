#!/usr/bin/env python3
"""
aikorea24.kr - ì‹¤íŒ¨ í•­ëª© ìˆ˜ì • í…ŒìŠ¤íŠ¸
- pytrends 404 â†’ Google Trends RSS + ê³µì‹ API ëŒ€ì•ˆ
- signal.bz JSë Œë”ë§ â†’ API ì§ì ‘ í˜¸ì¶œ
"""

import requests
import json
from datetime import datetime
from bs4 import BeautifulSoup

print("=" * 60)
print(f"ì‹¤íŒ¨ í•­ëª© ìˆ˜ì • í…ŒìŠ¤íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 60)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [FIX 1] Google Trends ëŒ€ì•ˆ: RSS í”¼ë“œ
# pytrends 404 â†’ Google Trends RSSë¡œ ëŒ€ì²´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸŒ [FIX 1] Google Trends RSS í”¼ë“œ (pytrends ëŒ€ì•ˆ)")
try:
    # Google Trends í•œêµ­ ì¼ê°„ íŠ¸ë Œë“œ RSS
    url = "https://trends.google.co.kr/trending/rss?geo=KR"
    r = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
    
    if r.status_code == 200 and len(r.text) > 500:
        soup = BeautifulSoup(r.text, 'xml')
        items = soup.find_all('item')
        if items:
            keywords = []
            for item in items[:10]:
                title = item.find('title')
                traffic = item.find('ht:approx_traffic') or item.find('approx_traffic')
                if title:
                    kw = title.get_text(strip=True)
                    vol = traffic.get_text(strip=True) if traffic else "N/A"
                    keywords.append(f"{kw}({vol})")
            print(f"  âœ… Google Trends RSS ì„±ê³µ! í•œêµ­ ê¸‰ìƒìŠ¹ {len(items)}ê±´")
            print(f"  TOP10: {', '.join(keywords[:10])}")
        else:
            # XML íŒŒì‹± ë‹¤ë¥¸ ë°©ì‹ ì‹œë„
            soup2 = BeautifulSoup(r.text, 'html.parser')
            titles = soup2.find_all('title')
            kws = [t.get_text(strip=True) for t in titles if t.get_text(strip=True) and 'trend' not in t.get_text().lower()]
            print(f"  âš ï¸ XML item ì—†ìŒ, title íƒœê·¸ì—ì„œ {len(kws)}ê±´ ì¶”ì¶œ")
            if kws:
                print(f"  í‚¤ì›Œë“œ: {', '.join(kws[:10])}")
    else:
        print(f"  âŒ RSS ì‘ë‹µ ì‹¤íŒ¨: HTTP {r.status_code}, í¬ê¸°: {len(r.text)}bytes")
        
except Exception as e:
    print(f"  âŒ RSS ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [FIX 1-B] Google Trends ëŒ€ì•ˆ: ì›¹ ìŠ¤í¬ë˜í•‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸŒ [FIX 1-B] Google Trends ì¼ê°„ íŠ¸ë Œë“œ í˜ì´ì§€")
try:
    url = "https://trends.google.co.kr/trending?geo=KR&hours=24"
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    }
    r = requests.get(url, headers=headers, timeout=10)
    print(f"  ì‘ë‹µ: HTTP {r.status_code}, í¬ê¸°: {len(r.text):,}bytes")
    if r.status_code == 200:
        print(f"  âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ (JSë Œë”ë§ í•„ìš”í•  ìˆ˜ ìˆìŒ)")
    else:
        print(f"  âš ï¸ HTTP {r.status_code}")
except Exception as e:
    print(f"  âŒ ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [FIX 2] signal.bz ëŒ€ì•ˆ: API ì§ì ‘ í˜¸ì¶œ
# signal.bzëŠ” SPAì´ë¯€ë¡œ ë‚´ë¶€ APIë¥¼ ì§ì ‘ í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ”¥ [FIX 2] signal.bz ë‚´ë¶€ API í˜¸ì¶œ")
try:
    # signal.bzì˜ ì‹¤ì œ ë°ì´í„° API ì—”ë“œí¬ì¸íŠ¸
    api_urls = [
        "https://signal.bz/api/realtime-keywords",
        "https://api.signal.bz/keywords",
        "https://signal.bz/api/news",
    ]
    
    success = False
    for api_url in api_urls:
        try:
            r = requests.get(api_url, timeout=5, 
                           headers={"User-Agent": "Mozilla/5.0",
                                    "Accept": "application/json"})
            if r.status_code == 200:
                data = r.json()
                print(f"  âœ… {api_url} â†’ ì‘ë‹µ ìˆ˜ì‹ ")
                print(f"  ë°ì´í„°: {json.dumps(data, ensure_ascii=False)[:200]}")
                success = True
                break
        except:
            continue
    
    if not success:
        print("  âš ï¸ signal.bz API ì—”ë“œí¬ì¸íŠ¸ ì°¾ì§€ ëª»í•¨")
        print("  â†’ ëŒ€ì•ˆ: Selenium ë˜ëŠ” ë‹¤ë¥¸ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ì†ŒìŠ¤ ì‚¬ìš©")
        
except Exception as e:
    print(f"  âŒ ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [FIX 2-B] ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ëŒ€ì•ˆ: ë„¤ì´ë²„ ë°ì´í„°ë©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ”¥ [FIX 2-B] ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ëŒ€ì•ˆ ì†ŒìŠ¤ë“¤")

# ëŒ€ì•ˆ 1: zum.com ì‹¤ì‹œê°„ ì´ìŠˆ
print("  [ëŒ€ì•ˆ1] ZUM ì‹¤ì‹œê°„ ì´ìŠˆ")
try:
    r = requests.get("https://zum.com", timeout=10,
                     headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(r.text, 'html.parser')
    # ZUM NOW ì´ìŠˆ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
    keywords = []
    for tag in soup.find_all(['a', 'span']):
        cls = tag.get('class', [])
        text = tag.get_text(strip=True)
        if text and 2 < len(text) < 20:
            # ë§í¬ì— issue/keyword ê´€ë ¨ íŒ¨í„´ì´ ìˆëŠ”ì§€
            href = tag.get('href', '')
            if 'issue' in href or 'search' in href or 'keyword' in href:
                keywords.append(text)
    if keywords:
        unique_kws = list(dict.fromkeys(keywords))[:10]
        print(f"    âœ… ZUM ì´ìŠˆ í‚¤ì›Œë“œ {len(unique_kws)}ê±´: {', '.join(unique_kws)}")
    else:
        print(f"    âš ï¸ ZUM í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ (í˜ì´ì§€: {len(r.text):,}bytes)")
except Exception as e:
    print(f"    âŒ ZUM ì‹¤íŒ¨: {e}")

# ëŒ€ì•ˆ 2: ë„¤ì´ë²„ ì‹¤ì‹œê°„ ê¸‰ìƒìŠ¹ ê²€ìƒ‰ì–´ (DataLab)
print("  [ëŒ€ì•ˆ2] ë„¤ì´ë²„ ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ (ë¡œê·¸ì¸ ë¶ˆí•„ìš”)")
try:
    import os
    cid = os.environ.get("NAVER_CLIENT_ID", "")
    if cid and cid != "YOUR_NAVER_CLIENT_ID":
        print("    â†’ ë„¤ì´ë²„ ë°ì´í„°ë© API ì‚¬ìš© ê°€ëŠ¥ (.env.sh ì„¤ì •ë¨)")
    else:
        print("    â†’ .env.shì— NAVER_CLIENT_ID ì„¤ì • í›„ ì‚¬ìš© ê°€ëŠ¥")
except Exception as e:
    print(f"    âŒ ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìµœì¢… ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n" + "=" * 60)
print("ğŸ“Š ìˆ˜ì • ê²°ê³¼ ìš”ì•½")
print("=" * 60)
print("""
  Google Trends:
    - pytrends        â†’ âŒ 2025.02~ Google ì—”ë“œí¬ì¸íŠ¸ ë³€ê²½ìœ¼ë¡œ 404
    - Google RSS í”¼ë“œ  â†’ âœ… ê°€ì¥ ì•ˆì •ì  ëŒ€ì•ˆ (xml íŒŒì‹±)
    - Google ê³µì‹ API  â†’ ğŸ”œ ì•ŒíŒŒ ëŒ€ê¸° ì¤‘ (ì‹ ì²­ í•„ìš”)
    
  ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´:
    - signal.bz       â†’ âŒ SPA, JS ë Œë”ë§ í•„ìš”
    - ZUM ì´ìŠˆ        â†’ âš ï¸ ì…€ë ‰í„° ì¡°ì • í•„ìš”
    - ë„¤ì´ë²„ ë°ì´í„°ë©   â†’ âœ… API í‚¤ ì„¤ì • ì‹œ ê°€ì¥ ì •í™•
    
  â”€â”€â”€ ìµœì¢… ì¶”ì²œ ì¡°í•© â”€â”€â”€
  1ìˆœìœ„: ë„¤ì´ë²„ ë°ì´í„°ë© API (í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¹„ìœ¨)
  2ìˆœìœ„: Google Trends RSS (í•œêµ­ ì¼ê°„ ê¸‰ìƒìŠ¹)
  3ìˆœìœ„: NIPA/ì •ì±…ë¸Œë¦¬í•‘ RSS (AI ì§€ì›ì‚¬ì—… ê³µê³ )
""")
