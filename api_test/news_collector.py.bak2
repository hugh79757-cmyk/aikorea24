#!/usr/bin/env python3
"""
aikorea24.kr 뉴스 수집기 v2.1
- AI 관련 뉴스만 3단계 정밀 필터링
- 중복 방지 (제목 해시)
- 수집 후 D1 저장
"""

import os, json, subprocess, urllib.request, urllib.parse, hashlib, re
from datetime import datetime
from xml.etree import ElementTree as ET
from html import unescape

def load_env(path):
    with open(path) as f:
        for line in f:
            line = line.strip()
            if line.startswith('#') or '=' not in line:
                continue
            line = line.replace('export ', '')
            key, val = line.split('=', 1)
            os.environ[key.strip()] = val.strip().strip('"').strip("'")

load_env('/Users/twinssn/Projects/aikorea24/api_test/.env.sh')

PROJECT_DIR = '/Users/twinssn/Projects/aikorea24'
NAVER_ID = os.environ.get('NAVER_CLIENT_ID', '')
NAVER_SECRET = os.environ.get('NAVER_CLIENT_SECRET', '')
DATA_KEY = os.environ.get('DATA_GO_KR_KEY', '')

def clean(text):
    text = unescape(text or '')
    return re.sub(r'<[^>]+>', '', text).strip()

# ===== AI 3단계 필터 =====
STRONG = ['AI', 'A.I', '인공지능', 'GPT', 'ChatGPT', '챗GPT', 'LLM',
    '생성형', '딥러닝', '머신러닝', '딥페이크', '자연어처리',
    '앤트로픽', 'Anthropic', '오픈AI', 'OpenAI', '클로드', 'Claude',
    'Gemini', '제미나이', 'Copilot', '코파일럿', '코덱스',
    'Midjourney', '미드저니', 'Stable Diffusion', 'DALL-E', 'Sora',
    'AI 바우처', 'AI바우처', 'AI 스타트업', '휴머노이드',
    '피지컬 AI', 'AI 서비스', 'AI 기반', 'AI 모드']

WEAK = ['데이터센터', '클라우드', '반도체', '엔비디아', 'GPU',
    '자율주행', '로봇', '알고리즘', '빅데이터', '테크', '4차 산업',
    '디지털 전환', '소프트웨어', '스타트업']

EXCLUDE = ['귀촌', '귀어', '귀농', '축산', '양식', '어업',
    '교복', '생리대', '시승', '전시장 이벤트', '부동산', '아파트',
    '야구', '축구', '농구', '올림픽', '날씨', '태풍', '폭설',
    '결혼', '출산', '장례', '과학관', '과학특강', '마약',
    '행정통합', '통합특별', '도서관', '연휴 이벤트', '르노',
    '교육청', '임대', '재건축']

def is_ai(title, desc=''):
    text = (title + ' ' + desc).upper()
    for kw in EXCLUDE:
        if kw.upper() in text: return False
    for kw in STRONG:
        if kw.upper() in text: return True
    weak_count = sum(1 for kw in WEAK if kw.upper() in text)
    return weak_count >= 2

# ===== 중복 체크 =====
def title_hash(title):
    normalized = re.sub(r'[^가-힣a-zA-Z0-9]', '', title)
    return hashlib.md5(normalized.encode()).hexdigest()

def get_existing():
    try:
        r = subprocess.run(
            ['npx', 'wrangler', 'd1', 'execute', 'aikorea24-db', '--remote',
             '--command', 'SELECT title FROM news', '--json'],
            capture_output=True, text=True, cwd=PROJECT_DIR, timeout=120)
        hashes = set()
        if r.returncode == 0 and r.stdout.strip():
            import json as _json
            data = _json.loads(r.stdout)
            # wrangler --json 출력: [{"results": [{"title": "..."}, ...]}]
            if isinstance(data, list) and data:
                results = data[0].get('results', [])
                for row in results:
                    t = row.get('title', '')
                    if t:
                        hashes.add(title_hash(t))
        print(f"  기존 D1 항목: {len(hashes)}개")
        return hashes
    except Exception as e:
        print(f"  get_existing 실패: {e}")
        return set()

# ===== 1. 과기부 사업공고 =====
def fetch_msit_announce(limit=30):
    url = f"http://apis.data.go.kr/1721000/msitannouncementinfo/businessAnnouncMentList?ServiceKey={DATA_KEY}&pageNo=1&numOfRows={limit}&returnType=json"
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        data = json.loads(urllib.request.urlopen(req, timeout=10).read())
        items = data['response'][1]['body']['items']
        results = []
        for entry in items:
            item = entry['item']
            title = clean(item.get('subject', ''))
            desc = f"담당: {item.get('deptName','')}"
            if is_ai(title, desc):
                results.append({'title': title, 'link': item.get('viewUrl', ''),
                    'description': desc, 'source': '과기부 사업공고',
                    'category': 'grant', 'pub_date': item.get('pressDt', '')})
        print(f"  과기부 사업공고: {len(results)}건")
        return results
    except Exception as e:
        print(f"  과기부 사업공고 실패: {e}"); return []

# ===== 2. 과기부 보도자료 =====
def fetch_msit_press(limit=20):
    url = f"http://apis.data.go.kr/1721000/msitpressreleaseinfo/pressReleaseList?ServiceKey={DATA_KEY}&pageNo=1&numOfRows={limit}&returnType=json"
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        data = json.loads(urllib.request.urlopen(req, timeout=10).read())
        items = data['response'][1]['body']['items']
        results = []
        for entry in items:
            item = entry['item']
            title = clean(item.get('subject', ''))
            desc = f"담당: {item.get('deptName','')}"
            if is_ai(title, desc):
                results.append({'title': title, 'link': item.get('viewUrl', ''),
                    'description': desc, 'source': '과기부 보도자료',
                    'category': 'policy', 'pub_date': item.get('pressDt', '')})
        print(f"  과기부 보도자료: {len(results)}건")
        return results
    except Exception as e:
        print(f"  과기부 보도자료 실패: {e}"); return []

# ===== 3. 정부24 혜택 =====
def fetch_gov_benefits(limit=50):
    url = f"https://api.odcloud.kr/api/gov24/v3/serviceList?page=1&perPage={limit}&serviceKey={DATA_KEY}"
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        data = json.loads(urllib.request.urlopen(req, timeout=10).read())
        results = []
        for item in data.get('data', []):
            name = item.get('서비스명', '')
            summary = item.get('서비스목적요약', '')
            if is_ai(name, summary):
                results.append({'title': name,
                    'link': f"https://www.gov.kr/portal/rcvfvrSvc/dtlEx/{item.get('서비스ID','')}",
                    'description': summary[:200], 'source': '정부24 혜택',
                    'category': 'benefit', 'pub_date': datetime.now().strftime('%Y-%m-%d')})
        print(f"  정부24 혜택: {len(results)}건")
        return results
    except Exception as e:
        print(f"  정부24 혜택 실패: {e}"); return []

# ===== 4. 네이버 뉴스 =====
QUERIES = ['인공지능 AI 서비스', 'ChatGPT 활용법', '생성형AI 스타트업',
    'AI 바우처 지원사업', '딥러닝 기술 트렌드', 'AI 정책 규제']

def fetch_naver(query, display=10):
    encoded = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encoded}&display={display}&sort=date"
    req = urllib.request.Request(url, headers={
        'X-Naver-Client-Id': NAVER_ID, 'X-Naver-Client-Secret': NAVER_SECRET})
    try:
        data = json.loads(urllib.request.urlopen(req, timeout=10).read())
        results = []
        for item in data.get('items', []):
            title = clean(item['title'])
            desc = clean(item['description'])
            if is_ai(title, desc):
                results.append({'title': title, 'link': item['link'],
                    'description': desc[:200], 'source': '네이버뉴스',
                    'category': 'news', 'pub_date': datetime.now().strftime('%Y-%m-%d')})
        return results
    except Exception as e:
        print(f"  네이버 '{query}' 실패: {e}"); return []

# ===== 5. RSS =====
RSS_FEEDS = [
    ('https://www.aitimes.com/rss/allArticle.xml', 'AI타임스'),
]

def fetch_rss(url, source_name, limit=15):
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        xml = urllib.request.urlopen(req, timeout=10).read()
        tree = ET.fromstring(xml)
        results = []
        for item in tree.findall('.//item')[:limit]:
            title = clean(item.findtext('title', ''))
            desc = clean(item.findtext('description', ''))
            if is_ai(title, desc):
                results.append({'title': title, 'link': item.findtext('link', ''),
                    'description': desc[:200], 'source': source_name,
                    'category': 'news', 'pub_date': datetime.now().strftime('%Y-%m-%d')})
        return results
    except Exception as e:
        print(f"  RSS {source_name} 실패: {e}"); return []
        
# ===== 6. 국가AI전략위원회 / 대통령실 브리핑 (네이버 뉴스 검색) =====
AI_POLICY_QUERIES = [
    'AI 기본사회 정책',
    '국가AI전략위원회',
    'AI 행동전략 정부',
    'AI 복지 지원 정부',
    'AI 접근성 디지털 격차',
    'AI 인재양성 교육부',
    'AI 바우처 중소기업',
    'AI 윤리 기본법',
]

def fetch_naver_policy():
    """정부 AI 정책 전용 네이버 뉴스 수집 (category='policy')"""
    results = []
    for q in AI_POLICY_QUERIES:
        encoded = urllib.parse.quote(q)
        url = f"https://openapi.naver.com/v1/search/news.json?query={encoded}&display=5&sort=date"
        req = urllib.request.Request(url, headers={
            'X-Naver-Client-Id': NAVER_ID,
            'X-Naver-Client-Secret': NAVER_SECRET
        })
        try:
            data = json.loads(urllib.request.urlopen(req, timeout=10).read())
            for item in data.get('items', []):
                title = clean(item['title'])
                desc = clean(item['description'])
                if is_ai(title, desc):
                    results.append({
                        'title': title,
                        'link': item['link'],
                        'description': desc[:200],
                        'source': '네이버뉴스',
                        'category': 'policy',   # ← 'news'가 아니라 'policy'
                        'pub_date': datetime.now().strftime('%Y-%m-%d')
                    })
        except Exception as e:
            print(f"  정책뉴스 '{q}' 실패: {e}")
    print(f"  정책 뉴스(네이버): {len(results)}건")
    return results


# ===== 7. 행안부 보도자료 (AI/디지털 관련) =====
def fetch_mois_press(limit=20):
    """행정안전부 보도자료에서 AI/디지털 관련 수집"""
    url = f"http://apis.data.go.kr/1741000/newPressRelease/getNewPressReleaseList?serviceKey={DATA_KEY}&pageNo=1&numOfRows={limit}&returnType=json"
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        data = json.loads(urllib.request.urlopen(req, timeout=10).read())
        items = data.get('response', [{}])
        if len(items) > 1:
            items = items[1].get('body', {}).get('items', [])
        else:
            items = []
        results = []
        for entry in items:
            item = entry.get('item', entry)
            title = clean(item.get('subject', item.get('title', '')))
            desc = clean(item.get('contents', item.get('description', '')))[:200]
            if is_ai(title, desc):
                results.append({
                    'title': title,
                    'link': item.get('viewUrl', item.get('link', '')),
                    'description': desc,
                    'source': '행안부 보도자료',
                    'category': 'policy',
                    'pub_date': item.get('pressDt', item.get('pubDate', ''))
                })
        print(f"  행안부 보도자료: {len(results)}건")
        return results
    except Exception as e:
        print(f"  행안부 보도자료 실패: {e}")
        return []


# ===== 8. 모두의 창업 프로젝트 뉴스 수집 =====
STARTUP_QUERIES = [
    'AI 스타트업 창업 지원',
    'AI 창업 바우처 지원사업',
    '중소벤처기업부 AI 창업',
    'AI 기반 창업 오디션',
]

def fetch_startup_news():
    results = []
    for q in STARTUP_QUERIES:
        encoded = urllib.parse.quote(q)
        url = f"https://openapi.naver.com/v1/search/news.json?query={encoded}&display=10&sort=date"
        req = urllib.request.Request(url, headers={
            'X-Naver-Client-Id': NAVER_ID,
            'X-Naver-Client-Secret': NAVER_SECRET
        })
        try:
            data = json.loads(urllib.request.urlopen(req, timeout=10).read())
            for item in data.get('items', []):
                title = clean(item['title'])
                desc = clean(item['description'])
                if not is_ai(title, desc):
                    continue
                results.append({
                    'title': title,
                    'link': item['link'],
                    'description': desc[:200],
                    'source': '네이버뉴스',
                    'category': 'startup',
                    'pub_date': datetime.now().strftime('%Y-%m-%d')
                })
        except Exception as e:
            print(f"  모두의창업 '{q}' 실패: {e}")
    print(f"  모두의 창업 뉴스: {len(results)}건")
    return results

# ===== 9. 복지 관련 뉴스 수집 =====
WELFARE_QUERIES = [
    'AI 돌봄 서비스 도입',
    'AI 장애인 접근성 기술',
    'AI 시니어 디지털 교육',
    'AI 사회안전망 복지',
    'AI 일자리 지원 정책',
]

def fetch_welfare_news():
    """AI+복지 관련 뉴스 수집 (category='benefit')"""
    results = []
    for q in WELFARE_QUERIES:
        encoded = urllib.parse.quote(q)
        url = f"https://openapi.naver.com/v1/search/news.json?query={encoded}&display=5&sort=date"
        req = urllib.request.Request(url, headers={
            'X-Naver-Client-Id': NAVER_ID,
            'X-Naver-Client-Secret': NAVER_SECRET
        })
        try:
            data = json.loads(urllib.request.urlopen(req, timeout=10).read())
            for item in data.get('items', []):
                title = clean(item['title'])
                desc = clean(item['description'])
                if not is_ai(title, desc):
                    continue
                results.append({
                    'title': title,
                    'link': item['link'],
                    'description': desc[:200],
                    'source': '네이버뉴스',
                    'category': 'benefit',
                    'pub_date': datetime.now().strftime('%Y-%m-%d')
                })
        except Exception as e:
            print(f"  복지뉴스 '{q}' 실패: {e}")
    print(f"  복지/접근성 뉴스: {len(results)}건")
    return results
        

# ===== D1 저장 (배치) =====

def fetch_bizinfo_grants():
    """[11] 기업마당 소상공인 AI 지원사업 공고"""
    api_key = os.environ.get('BIZINFO_API_KEY', '')
    if not api_key:
        print("  BIZINFO_API_KEY 없음, 스킵")
        return []

    results = []
    existing = get_existing()
    ai_strong = ['AI', '인공지능', 'AI바우처', '데이터바우처', '스마트상점', '키오스크',
                 '챗봇', '디지털커머스', '스마트공장']
    ai_weak = ['디지털전환', '디지털', '스마트', '빅데이터', '클라우드', '자동화',
               '로봇', 'DX', 'ICT', '온라인', '플랫폼']
    biz_words = ['소상공인', '소기업', '소공인', '자영업', '영세', '골목상권', '전통시장']

    try:
        url = 'https://www.bizinfo.go.kr/uss/rss/bizinfoApi.do'
        params = f'crtfcKey={api_key}&dataType=json&searchCnt=200&pageUnit=200&pageIndex=1'
        full_url = f'{url}?{params}'

        req = urllib.request.Request(full_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=30) as resp:
            raw = resp.read().decode('utf-8')
            data = json.loads(raw)

        items = data.get('jsonArray', [])
        total = items[0].get('totCnt', '?') if items else 0
        print(f"  기업마당 전체 공고: {total}건, 가져온 건: {len(items)}건")

        count = 0
        for item in items:
            title = clean(item.get('pblancNm', ''))
            desc = clean(item.get('bsnsSumryCn', ''))
            target = item.get('trgetNm', '')
            org = item.get('jrsdInsttNm', '')
            exc_org = item.get('excInsttNm', '')
            hashtags = item.get('hashtags', '')
            period = item.get('reqstBeginEndDe', '')
            purl = item.get('pblancUrl', '')
            link = f'https://www.bizinfo.go.kr{purl}' if purl and not purl.startswith('http') else purl

            full_text = f'{title} {desc} {target} {hashtags}'
            has_strong = any(kw.lower() in full_text.lower() for kw in ai_strong)
            has_weak = any(kw.lower() in full_text.lower() for kw in ai_weak)
            has_biz = any(w in full_text for w in biz_words)

            if (has_strong and has_biz) or (has_strong and '중소기업' in target) or (has_weak and has_biz):
                if title and title_hash(title) not in existing:
                    summary = desc[:300] if desc else ''
                    info_parts = []
                    if org: info_parts.append(f'소관: {org}')
                    if exc_org: info_parts.append(f'수행: {exc_org}')
                    if target: info_parts.append(f'대상: {target}')
                    if period: info_parts.append(f'신청기간: {period}')
                    info_line = ' | '.join(info_parts)
                    final_desc = f'{info_line}\n{summary}' if summary else info_line

                    results.append({
                        'title': title[:200],
                        'link': link,
                        'description': final_desc[:500],
                        'source': org or '기업마당',
                        'category': 'grant',
                        'pub_date': period.split('~')[0].strip() if '~' in period else datetime.now().strftime('%Y-%m-%d')
                    })
                    count += 1

        print(f"  AI/디지털/소상공인 필터 통과: {count}건")
    except Exception as e:
        print(f"  기업마당 실패: {e}")
        import traceback
        traceback.print_exc()

    return results


def save_to_d1(articles):
    existing = get_existing()
    sql_lines = []
    skipped = 0
    for a in articles:
        h = title_hash(a['title'])
        if h in existing: skipped += 1; continue
        t = a['title'].replace("'", "''")[:200]
        l = a['link'].replace("'", "''")[:500]
        d = a['description'].replace("'", "''")[:500]
        s = a['source'].replace("'", "''")
        c = a['category']
        p = a.get('pub_date', datetime.now().strftime('%Y-%m-%d'))
        sql_lines.append(f"INSERT OR IGNORE INTO news (title, link, description, source, category, pub_date) VALUES ('{t}', '{l}', '{d}', '{s}', '{c}', '{p}');")
    if not sql_lines:
        print("  저장할 신규 항목 없음")
        return 0, skipped
    # SQL 파일로 저장 후 한번에 실행
    sql_path = os.path.join(PROJECT_DIR, 'api_test', '_batch_insert.sql')
    # 50개씩 나눠서 실행 (D1 제한 대응)
    saved = 0
    batch_size = 50
    for i in range(0, len(sql_lines), batch_size):
        batch = sql_lines[i:i+batch_size]
        with open(sql_path, 'w') as f:
            f.write('\n'.join(batch))
        try:
            r = subprocess.run(
                ['npx', 'wrangler', 'd1', 'execute', 'aikorea24-db', '--remote', '--file', sql_path],
                capture_output=True, text=True, cwd=PROJECT_DIR, timeout=60)
            if r.returncode == 0:
                saved += len(batch)
                print(f"  배치 {i//batch_size+1}: {len(batch)}건 저장")
            else:
                print(f"  배치 {i//batch_size+1} 실패: {r.stderr[:200]}")
        except Exception as e:
            print(f"  배치 에러: {e}")
    # 정리
    try: os.remove(sql_path)
    except: pass
    return saved, skipped

# ============================================
# 정부 공문서 AI 학습데이터 API 연동
# ============================================
GOV_DOC_BASE = 'http://apis.data.go.kr/1741000/publicDoc'
GOV_DOC_ENDPOINTS = {
    'getDocPress': '보도자료',
    'getDocReport': '정책보고서',
    'getDocSpeech': '연설문',
}
GOV_DOC_KEYWORDS = ['AI', '인공지능', '디지털', '데이터', '클라우드', '스마트', '자율주행', '로봇', '반도체', '소프트웨어']

def fetch_gov_docs():
    """정부 공문서 AI 학습데이터에서 AI 관련 문서 수집"""
    api_key = os.environ.get('DATA_GO_KR_KEY', '')
    if not api_key:
        print('  DATA_GO_KR_KEY 없음 - 건너뜀')
        return []

    items = []
    for endpoint, doc_type in GOV_DOC_ENDPOINTS.items():
        for kw in GOV_DOC_KEYWORDS:
            try:
                params = urllib.parse.urlencode({'serviceKey': api_key, 'format': 'json', 'numOfRows': 10, 'pageNo': 1, 'title': kw})
                req = urllib.request.Request(f'{GOV_DOC_BASE}/{endpoint}?{params}', headers={'User-Agent': 'Mozilla/5.0'})
                data = json.loads(urllib.request.urlopen(req, timeout=15).read())
                body = data.get('response', {}).get('body', {})
                results = body.get('resultList', [])
                if isinstance(results, dict):
                    results = [results]
                for item in results:
                    meta = item.get('meta', item) if isinstance(item, dict) else {}
                    text_data = ''
                    if isinstance(item, dict) and 'data' in item:
                        text_data = item['data'].get('text', '')
                    title = meta.get('title', '')
                    if not title:
                        continue
                    combined = title.upper()
                    strong = any(w.upper() in combined for w in ['AI', '인공지능', 'GPT', '딥러닝', '머신러닝', 'LLM', '생성형', '챗봇'])
                    weak_cnt = sum(1 for w in ['디지털', '데이터', '클라우드', '스마트', '로봇', '반도체', '소프트웨어'] if w.upper() in combined)
                    if not strong and weak_cnt < 2:
                        continue
                    preview = text_data[:300] if text_data else f'{doc_type} - {meta.get("ministry", "")} ({meta.get("date", "")})'
                    items.append({
                        'title': title,
                        'link': 'https://www.data.go.kr/data/15125451/openapi.do',
                        'description': preview,
                        'source': f'정부공문서({doc_type})',
                        'category': 'policy',
                        'pub_date': meta.get('date', '')
                    })
            except Exception as e:
                pass
    # 제목 기준 중복 제거
    seen = set()
    unique = []
    for item in items:
        if item['title'] not in seen:
            seen.add(item['title'])
            unique.append(item)
    print(f'  정부공문서 AI관련: {len(unique)}건')
    return unique

# ===== 메인 =====
def main():
    print('=' * 60)
    print(f"aikorea24 뉴스 수집 v3.0 - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print('=' * 60)
    all_items = []

    print('\n[1] 과기부 사업공고')
    all_items.extend(fetch_msit_announce())

    print('\n[2] 과기부 보도자료')
    all_items.extend(fetch_msit_press())

    print('\n[3] 정부24 혜택')
    all_items.extend(fetch_gov_benefits())

    print('\n[4] 네이버 뉴스')
    for q in QUERIES:
        r = fetch_naver(q)
        all_items.extend(r)
        print(f"  '{q}': {len(r)}건")

    print('\n[5] RSS')
    for url, name in RSS_FEEDS:
        r = fetch_rss(url, name)
        all_items.extend(r)
        print(f"  {name}: {len(r)}건")

    print('\n[6] 정부 AI 정책 뉴스')
    all_items.extend(fetch_naver_policy())

    print('\n[7] 행안부 보도자료')
    all_items.extend(fetch_mois_press())

    print('\n[8] 모두의 창업 프로젝트 뉴스')
    all_items.extend(fetch_startup_news())

    print('\n[9] AI 복지/접근성 뉴스')
    all_items.extend(fetch_welfare_news())

    print('\n[10] 정부 공문서')
    all_items.extend(fetch_gov_docs())

    print("\n[11] 기업마당 소상공인 AI 지원사업")
    all_items.extend(fetch_bizinfo_grants())

    print(f"\n총 수집: {len(all_items)}건")
    print('\nD1 저장 중...')
    saved, skipped = save_to_d1(all_items)
    print(f"  신규: {saved}건, 중복 스킵: {skipped}건")
    print('=' * 60)

if __name__ == '__main__':
    main()
